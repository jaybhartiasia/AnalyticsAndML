{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "colab": {
      "name": "1.2 Quasi-constant_features.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay10949/AnalyticsAndML/blob/master/FeatureSelection/FilterMethods1_2_Quasi_constant_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-_zQZA2lucF",
        "colab_type": "text"
      },
      "source": [
        "## Quasi-constant features\n",
        "\n",
        "Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little if any information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So you should be careful when removing these type of features.\n",
        "\n",
        "Identifying and removing quasi-constant features, is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
        "\n",
        "Here I will demonstrate how to identify quasi-constant features using the Santander Customer Satisfaction dataset from Kaggle. \n",
        "\n",
        "To identify constant features, we can use the VarianceThreshold function from sklearn, or we can code it ourselves. I will show 2 snippets of code with both procedures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6VT9liylucM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GExzXnGslucq",
        "colab_type": "code",
        "colab": {},
        "outputId": "34231c65-91e3-4513-f544-8a5c2bfb1009"
      },
      "source": [
        "# load the Santander customer satisfaction dataset from Kaggle\n",
        "# I load just a few rows for the demonstration\n",
        "data = pd.read_csv('santander.csv', nrows=50000)\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lounIzqlludD",
        "colab_type": "code",
        "colab": {},
        "outputId": "d49ef1cd-2813-44c9-f477-13afd41d7c2d"
      },
      "source": [
        "# check the presence of null data.\n",
        "# The snippets below will be able to compare nan values between 2 columns,\n",
        "# so in principle missing data are not a problem.\n",
        "# in any case, we see that there are no missing data in this dataset\n",
        "\n",
        "[col for col in data.columns if data[col].isnull().sum() > 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HWdb7DHludR",
        "colab_type": "text"
      },
      "source": [
        "### Important\n",
        "\n",
        "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6b6hXvlludX",
        "colab_type": "code",
        "colab": {},
        "outputId": "a6a0b421-fb92-4d74-c252-eefb7cfb4b80"
      },
      "source": [
        "# separate train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['TARGET'], axis=1),\n",
        "    data['TARGET'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 370), (15000, 370))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y01Rv1kXludp",
        "colab_type": "text"
      },
      "source": [
        "### Remove constant features\n",
        "\n",
        "First, I will remove constant features like I did in the previous lecture. This will allow a better visualisation of the quasi-constant ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSWoROuSludt",
        "colab_type": "code",
        "colab": {},
        "outputId": "6f88b292-d150-4e71-a8a7-45f8396d869f"
      },
      "source": [
        "# using the code from the previous lecture\n",
        "# I remove 58 constant features\n",
        "\n",
        "constant_features = [\n",
        "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
        "]\n",
        "\n",
        "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 312), (15000, 312))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ7sm869lud6",
        "colab_type": "text"
      },
      "source": [
        "## Removing quasi-constant features\n",
        "### Using variance threshold from sklearn\n",
        "\n",
        "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesnâ€™t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples.\n",
        "\n",
        "Here, I will change the default threshold to remove almost / quasi-constant features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFa7KhPzlud8",
        "colab_type": "code",
        "colab": {},
        "outputId": "77a6601b-155b-48cb-a5f7-d75e708c0bd7"
      },
      "source": [
        "sel = VarianceThreshold(\n",
        "    threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
        "\n",
        "sel.fit(X_train)  # fit finds the features with low variance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VarianceThreshold(threshold=0.01)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we4W43uSlueN",
        "colab_type": "code",
        "colab": {},
        "outputId": "e788c13c-46a3-4c44-e36e-8b0815caebee"
      },
      "source": [
        "# get_support is a boolean vector that indicates which features \n",
        "# are retained. If we sum over get_support, we get the number\n",
        "# of features that are not quasi-constant\n",
        "sum(sel.get_support())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68s1Y78Elueb",
        "colab_type": "code",
        "colab": {},
        "outputId": "1456868f-08bd-4f51-9f72-8bb333b2b157"
      },
      "source": [
        "# another way of doing the above operation:\n",
        "len(X_train.columns[sel.get_support()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uviyZvl-luer",
        "colab_type": "code",
        "colab": {},
        "outputId": "b927df2c-7565-4c36-9f3e-fd3e37e66e69"
      },
      "source": [
        "# finally we can print the quasi-constant features\n",
        "print(\n",
        "    len([\n",
        "        x for x in X_train.columns\n",
        "        if x not in X_train.columns[sel.get_support()]\n",
        "    ]))\n",
        "\n",
        "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ind_var1',\n",
              " 'ind_var6_0',\n",
              " 'ind_var6',\n",
              " 'ind_var14',\n",
              " 'ind_var17_0',\n",
              " 'ind_var17',\n",
              " 'ind_var18_0',\n",
              " 'ind_var18',\n",
              " 'ind_var19',\n",
              " 'ind_var20_0',\n",
              " 'ind_var20',\n",
              " 'ind_var29_0',\n",
              " 'ind_var29',\n",
              " 'ind_var30_0',\n",
              " 'ind_var31_0',\n",
              " 'ind_var31',\n",
              " 'ind_var32_cte',\n",
              " 'ind_var32_0',\n",
              " 'ind_var32',\n",
              " 'ind_var33_0',\n",
              " 'ind_var33',\n",
              " 'ind_var40',\n",
              " 'ind_var39',\n",
              " 'ind_var44_0',\n",
              " 'ind_var44',\n",
              " 'num_var6_0',\n",
              " 'num_var6',\n",
              " 'num_var18_0',\n",
              " 'num_var18',\n",
              " 'num_op_var40_hace3',\n",
              " 'num_var29_0',\n",
              " 'num_var29',\n",
              " 'num_var33',\n",
              " 'ind_var7_emit_ult1',\n",
              " 'ind_var7_recib_ult1',\n",
              " 'num_aport_var17_hace3',\n",
              " 'num_aport_var33_hace3',\n",
              " 'num_aport_var33_ult1',\n",
              " 'num_var7_emit_ult1',\n",
              " 'num_meses_var17_ult3',\n",
              " 'num_meses_var29_ult3',\n",
              " 'num_meses_var33_ult3',\n",
              " 'num_meses_var44_ult3',\n",
              " 'num_reemb_var13_ult1',\n",
              " 'num_trasp_var17_in_hace3',\n",
              " 'num_trasp_var17_in_ult1',\n",
              " 'num_trasp_var17_out_ult1',\n",
              " 'num_trasp_var33_in_hace3',\n",
              " 'num_trasp_var33_in_ult1',\n",
              " 'num_trasp_var33_out_ult1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f12wIhE6lue5",
        "colab_type": "text"
      },
      "source": [
        "We can see that 50 columns / variables are almost constant. This means that 50 variables show predominantly one value for ~99% the observations of the training set. Let's see below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn3XARQjlue-",
        "colab_type": "code",
        "colab": {},
        "outputId": "979ff630-37b3-4b91-d1df-02ea79180cbd"
      },
      "source": [
        "# percentage of observations showing each of the different values\n",
        "X_train['ind_var31'].value_counts() / np.float(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.996486\n",
              "1    0.003514\n",
              "Name: ind_var31, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTrzjvGslufN",
        "colab_type": "text"
      },
      "source": [
        "We can see that > 99% of the observations show one value, 0. Therefore, this features is almost constant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMDQ8-EOlufR",
        "colab_type": "code",
        "colab": {},
        "outputId": "1acb8feb-9ead-4dd1-af2a-f97cb9157b66"
      },
      "source": [
        "# we can then remove the features like this\n",
        "X_train = sel.transform(X_train)\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 262), (15000, 262))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp1_rulllufh",
        "colab_type": "text"
      },
      "source": [
        "By removing constant and almost constant features, we reduced the feature space from 370 to 261. More than 100 features were removed from the present dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPGryq2vlufx",
        "colab_type": "text"
      },
      "source": [
        "### Coding it ourselves\n",
        "\n",
        "First, I will reload the dataset and remove the constant features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UxyQFQ8lufz",
        "colab_type": "code",
        "colab": {},
        "outputId": "4c2c3ccd-b9b6-4b51-eb05-a7b21d8a6cf2"
      },
      "source": [
        "# load the dataset\n",
        "data = pd.read_csv('santander.csv', nrows=50000)\n",
        "\n",
        "# separate train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['TARGET'], axis=1),\n",
        "    data['TARGET'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "# remove constant features\n",
        "# using the code from the previous lecture\n",
        "constant_features = [\n",
        "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
        "]\n",
        "\n",
        "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 312), (15000, 312))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7v2irFXAluf_",
        "colab_type": "code",
        "colab": {},
        "outputId": "072c5b18-7edc-4c8f-9b55-f7f15805c3c7"
      },
      "source": [
        "quasi_constant_feat = []\n",
        "for feature in X_train.columns:\n",
        "\n",
        "    # find the predominant value\n",
        "    predominant = (X_train[feature].value_counts() / np.float(\n",
        "        len(X_train))).sort_values(ascending=False).values[0]\n",
        "\n",
        "    # evaluate predominant feature\n",
        "    if predominant > 0.998:\n",
        "        quasi_constant_feat.append(feature)\n",
        "\n",
        "len(quasi_constant_feat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaBgaGzPlugL",
        "colab_type": "text"
      },
      "source": [
        "Our method was a bit more aggressive than VarianceThreshold from sklearn with the threshold that we selected above. It found 119 features that show predominantly 1 value for the majority of the observations. Let's see how some of the quasi constant features look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4BCpbEblugN",
        "colab_type": "code",
        "colab": {},
        "outputId": "f6d8c693-0113-40db-8779-b835bf9b8bf3"
      },
      "source": [
        "# select the first one from the list\n",
        "quasi_constant_feat[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'imp_op_var40_efect_ult1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "duUTTfTdlugV",
        "colab_type": "code",
        "colab": {},
        "outputId": "336b97ab-7df2-4b29-d0da-0cc7cbade3b6"
      },
      "source": [
        "X_train['imp_op_var40_efect_ult1'].value_counts() / np.float(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00       0.999400\n",
              "900.00     0.000086\n",
              "60.00      0.000057\n",
              "1800.00    0.000057\n",
              "600.00     0.000057\n",
              "930.00     0.000029\n",
              "420.00     0.000029\n",
              "74.28      0.000029\n",
              "270.00     0.000029\n",
              "1200.00    0.000029\n",
              "6600.00    0.000029\n",
              "870.00     0.000029\n",
              "750.00     0.000029\n",
              "300.00     0.000029\n",
              "120.00     0.000029\n",
              "210.00     0.000029\n",
              "150.00     0.000029\n",
              "Name: imp_op_var40_efect_ult1, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtfGQDi9lugc",
        "colab_type": "text"
      },
      "source": [
        "The feature shows 0 for more than 99.9% of the observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-FbWcKnlugf",
        "colab_type": "text"
      },
      "source": [
        "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
      ]
    }
  ]
}
